{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão de Dados - Reamostragem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação Cruzada: Avaliando a performance dos estimadores\n",
    "\n",
    "Treinar um modelo de aprendizagem e testá-lo nos mesmos dados é um erro metodológico: pode gerar um modelo capaz de repetir perfeitamente os rótulos das amostras já conhecidas mas que falha ao predizer o valor de novos dados desconhecidos. Esse problema, como já vimos, é chamado de overfitting. Uma prática comum para evitá-lo é manter uma parte dos dados disponíveis como conjunto de teste. Abaixo temos um fluxograma típico do fluxo de treinamento com otimização de hiper-parâmetros com validação cruzada (_cross validation_ ). Os melhores parâmetros podem ser encontrados utilizando técnicas de busca em grade, busca aleatória ou otimização meta-heurística.\n",
    "\n",
    "<img src='assets/grid_search_workflow.png' width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Scikit-Learn, podemos separar rápidamente nosso conjunto de dados em treino e teste com a já conhecida função `train_test_split`. Vamos carregar o dataset iris e treinar o Regressor Logístico nele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n",
      "Sample: [5.1 3.5 1.4 0.2]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "print(X.shape, y.shape)\n",
    "print(\"Sample:\", X[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos separar o conjunto de dados usando 60% para treinamento e 40% para teste (avaliação) do nosso classificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape, y_train.shape =  (90, 4) (90,)\n",
      "X_test.shape, y_test.shape =  (60, 4) (60,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "print('X_train.shape, y_train.shape = ', X_train.shape, y_train.shape)\n",
    "\n",
    "print('X_test.shape, y_test.shape = ', X_test.shape, y_test.shape)\n",
    "\n",
    "model = LogisticRegression(C=1,random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando avaliamos diferentes configurações de hyper-parâmetros, como por exemplo o $C$ no Regressor Logístico, ainda existe o risco de _overfitting_ no conjunto de testes por que o valor pode ser ajustado até que o resultado seja ótimizado. Assim, o conhecimento sobre os dados de teste podem \"vazar\" para o modelo e as métricas de avaliação deixam de reportar a performance real do modelo num cenário generalizado (com amostras desconhecidas). \n",
    "\n",
    "Para resolver esse problema, outra parte do _dataset_ pode ser mantida, chamada de \"conjunto de validação\": treinamento é feito no conjunto de treinamento, na sequência o conjunto de validação é usado para avaliar o modelo, e após finalizar o treinamento, a avaliação do modelo em um cenário desconhecido é feita usando o conjunto de teste. \n",
    "\n",
    "No entanto, ao particionar os dados disponíveis em 3 conjuntos, reduzimos drasticamente o número de amostras que podem ser usadas para treinar o modelo, e os resultados podem depender de uma escolha aleatória particular do par de conjuntos (treinamento, validação).\n",
    "\n",
    "A solução para esse problema é a validação cruzada (CV). Um conjunto de teste continua sendo separado para a avaliação final, mas o conjunto de validação não é mais necessário. Na abordagem mais básica, chamada $k$-fold CV, o conjunto de treinamento é dividido $k$ conjuntos menores (outras abordagens seguem os mesmos princípios). O procedimento a seguir é executado para cada um dos $k$ \"folds\":\n",
    "\n",
    "- O modelo é treinado usando $k-1$ _folds_ como dados de treinamento;\n",
    "\n",
    "- O modelo resultante é validado nos dados restantes, i.e., esses dados são usados como teste para computar a performance do modelo;\n",
    "\n",
    "A média das métricas reportadas pelo $k$-fold CV é computada. Essa abordagem é cara em termos computacionais, mas não desperdiça dados como quando separamos um conjunto de validação, sendo essa sua maior vantagem quando consideramos _datasets_ pequenos.\n",
    "\n",
    "<img src='assets/grid_search_cross_validation.png' width=500px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computando métricas com validação cruzada\n",
    "\n",
    "O modo mais fácil de se computar o resultado da validação cruzada é usando a função `cross_val_score`, passando como parâmetro o estimador e o dataset.\n",
    "\n",
    "O exemplo a seguir demonstra como estimar a acurácia do Regressor Logístico sobre o dataset _iris_ dividindo os dados, ajustando o modelo e computando os pontos 5 vezes consecutivas, com diferentes divisões do conjunto de treinamento a cada execução:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 1.         0.93333333 0.96666667 1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# computa diretamente os valores as métricas de saída para cada execução da validação cruzada\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valor médio e o desvio padrão podem ser computado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98 de acurácia com desvio padrão de 0.02\n"
     ]
    }
   ],
   "source": [
    "print(\"%0.2f de acurácia com desvio padrão de %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valor computado a cada iteração do CV é a métrica padrão do estimador. É possível trocá-la usando o parâmetro scoring: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96658312 1.         0.93265993 0.96658312 1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "scores = cross_val_score(\n",
    "    model, X, y, cv=5, scoring='f1_macro')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outras métricas disponíveis podem ser encontradas [aqui](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter). No caso do _dataset_ iris, o número de amostras por classe é balanceado, então o F1-score e a acurácia são quase iguais.\n",
    "\n",
    "Quando o argumento cv é um inteiro `cross_val_score` usa as estratégias [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold) ou [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold), dependendo do caso.\n",
    "\n",
    "Também é possível usar outras estratégias de validação cruzada passando um iterador, como, por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.93333333, 0.95555556, 0.91111111, 0.97777778])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "n_samples = X.shape[0]\n",
    "\n",
    "# gera os 5 splits\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "cross_val_score(model, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação cruzada com transformação dos dados \n",
    "\n",
    "Assim como testar nosso modelo em dados não usados durante o treinamento, pré-processamento (como normalização, selecão de característica, etc.) e outras transformações similares devem ser executadas no conjunto de treinamento e aplicadas no conjunto de teste para predição:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# divide os dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "# cria um pré-processador para normalizar os dados\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "# transforma os dados de treinamento\n",
    "X_train_transformed = scaler.transform(X_train)\n",
    "\n",
    "# treina o modelo\n",
    "model = LogisticRegression(C=1,random_state=0).fit(X_train_transformed, y_train)\n",
    "\n",
    "# transforma os dados de teste\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "\n",
    "# computa o resultado\n",
    "model.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando o método [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) deixa mais fácil organizar o processo, executando o comando com a validação cruzada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.91111111, 0.95555556, 0.93333333, 0.95555556])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), LogisticRegression(random_state=0))\n",
    "cross_val_score(clf, X, y, cv=cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A função `cross_validate` e a avaliação de múltiplas métricas\n",
    "\n",
    "A função `cross_validate` se diferencia da função `cross_val_score` de 2 maneiras:\n",
    "\n",
    "- ela permite especificar multiplas métricas para avaliação.\n",
    "\n",
    "- ela retorna um dicionário contendo as métricas `fit-times`, `score-times` (e opcionalmente os resultados do treinamento e o modelo treinado), além dos resultados sobre o conjunto de testes.\n",
    "\n",
    "Para avaliar uma única métrica, onde o parâmetro scoring é uma _string_, _callable_ ou _None_, as chaves do dicionário serão `['test_score', 'fit_time', 'score_time']`.\n",
    "\n",
    "Para avaliar múltiplas métricas, o valor retornado é um dicionário com as seguintes chaves: `['test_<scorer1_name>', 'test_<scorer2_name>', 'test_<scorer...>', 'fit_time', 'score_time']`\n",
    "\n",
    "`return_train_score` é setado para `False` por padrão para economizar tempo de processamento. para avaliar o resultados sobre o conjunto de treinamento é necessário setar esse valor para `True`.\n",
    "\n",
    "Você também pode armazenar os modelos treinados setando `return_estimator=True`.\n",
    "\n",
    "As múltiplas métricas podem ser especificadas tanto como uma lista, tupla, ou conjunto de nomes de marcadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fit_time', 'score_time', 'test_precision_macro', 'test_recall_macro']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.96969697, 1.        , 0.94444444, 0.96969697, 1.        ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# métricas a serem computadas\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "\n",
    "# definindo o modelo\n",
    "model = LogisticRegression(random_state=0)\n",
    "\n",
    "# treinando o modelo com validação cruzada - Usando strings no scoring\n",
    "scores = cross_validate(model, X, y, scoring=scoring)\n",
    "# imprimindo as chaves\n",
    "print(sorted(scores.keys()))\n",
    "\n",
    "print(scores['test_precision_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou como um dicionário mapeando os marcadores para uma função:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fit_time', 'score_time', 'test_prec_macro', 'test_rec_macro', 'train_prec_macro', 'train_rec_macro']\n",
      "[0.92213428 0.86981982 0.94089825 0.93816602 0.89770914]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# monta o conjunto de métricas a ser retornado usando strings ('precision_macro') e callable (make_scorer)\n",
    "scoring = {'prec_macro': 'precision_macro',\n",
    "           'rec_macro': make_scorer(recall_score, average='macro')}\n",
    "\n",
    "# treinando o modelo com validação cruzada - return_train_score=True para retornar os resultados sobre \n",
    "#    o conjunto de treinamento\n",
    "scores = cross_validate(model, X, y, scoring=scoring,\n",
    "                        cv=5, return_train_score=True)\n",
    "print(sorted(scores.keys()))\n",
    "\n",
    "#scores['train_rec_macro']\n",
    "print(scores['test_rec_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo de validação cruzada usando uma única métrica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['estimator', 'fit_time', 'score_time', 'test_score']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# passando return_estimator=True para retornar o modelo treinado\n",
    "scores = cross_validate(model, X, y,\n",
    "                        scoring='precision_macro', cv=5,\n",
    "                        return_estimator=True)\n",
    "sorted(scores.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtendo os rótulos estimados com validação cruzada\n",
    "\n",
    "A função [cross_val_predict](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict) tem uma interface similar à `cross_val_score`, mas retorna os rótulos para cada amostra no momento em que foi classificada. O método não é indicado pois as amostras são agrupadas de forma aleatória e essa classificação dependerá do agrupamento.\n",
    "\n",
    "Todo caso, ainda pode ser útil em 2 situações:\n",
    "1. visualização dos dados obtidos de diferentes modelos\n",
    "2. mistura de modelos, utilizado, por exemplo, em _ensamble_ de métodos (quando utilizamos a votação entre vários classificadores para encontrar o melhor resultado).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteradores de validação cruzada\n",
    "\n",
    "### Validação cruzada em dados independentes e distribuídos de forma idêntica\n",
    "\n",
    "Assumir que os dados são independentes e distribuídos de forma idêntica (i.i.d.) é assumir que todas as amostras foram gerados a partir do mesmo processo de distribuição.\n",
    "\n",
    "Para isso, podemos usar o famoso $k$-fold:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $K$-fold\n",
    "\n",
    "[KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold) divide todas as amostras em grupos de amostras, chamados de _folds_ (se $k=n$, o modelo é equivalente à estratégia Leave One Out), de tamanhos iguais (se possível). O modelo é aprendido usando $k-1$ _folds_ e o _fold_ restante é usado pra teste.\n",
    "\n",
    "Exemplo de validação cruzada 2-_fold_ em um _dataset_ com 4 amostras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Treinamento: [2 3] Teste: [0 1]\n",
      "Fold 2 - Treinamento: [0 1] Teste: [2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = [\"a\", \"b\", \"c\", \"d\"]\n",
    "kf = KFold(n_splits=2)\n",
    "for i, (train, test) in enumerate(kf.split(X)):\n",
    "    # printa os indices dos conjuntos de treinamento e teste\n",
    "    print(\"Fold %s - Treinamento: %s Teste: %s\" % (i+1, train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada _fold_ é constituido por 2 arrays: o primeiro está relacionado ao conjunto de treinamento e o segundo ao conjunto de teste. Sendo assim, poderiamos criar os conjuntos de treino/teste com os indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train = \n",
      " [[0. 0.]\n",
      " [1. 1.]]\n",
      "X_test = \n",
      " [[-1. -1.]\n",
      " [ 2.  2.]]\n",
      "y_train =  [0 1]\n",
      "y_test =  [0 1]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0., 0.], [1., 1.], [-1., -1.], [2., 2.]])\n",
    "y = np.array([0, 1, 0, 1])\n",
    "X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "\n",
    "# considerando os indices treino [0 1] e teste [2 3] acima, temos\n",
    "print('X_train = \\n', X_train)\n",
    "print('X_test = \\n', X_test)\n",
    "print('y_train = ', y_train)\n",
    "print('y_test = ', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outros métodos para dados independentes e distribuídos de forma idêntica\n",
    "\n",
    "- [RepeatedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html#sklearn.model_selection.RepeatedKFold) - repete $k$-_folds_ $n$ vezes\n",
    "- [Leave One Out (LOO)](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut) - similar ao $k$-_folds_ com $k=$ ao número de amostras\n",
    "- [Leave P Out (LPO)](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePOut.html#sklearn.model_selection.LeavePOut) - similar ao LOO, deixando $p$ amostras fora do processo. Nesse caso pode haver sobreposição de amostras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação cruzada com estratificação baseada nos rótulos \n",
    "\n",
    "\n",
    "Alguns problemas de classificação apresentam uma distribuição de classes altamente desbalanceadas. Nesses casos, é recomendado usar [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold), que assegura a frequência e tenta preservar, aproximadamente, a distribuição das classes em cada divisão dos conjuntos de treinamento e teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified k-fold\n",
    "\n",
    "[StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) é uma variação do $k$-fold que retorna os _folds_ estratificados: cada conjunto contém aproximadamente a mesma proporção de amostras de cada classe que o _dataset_ completo.\n",
    "\n",
    "Aqui temos um exemplo de validação cruzada 3-_fold_ estratificada em um conjunto de dados com $50$ amostras com 2 classes desbalanceadas. Mostraremos o número de amostras de cada classe e compararemos com o $k$-_fold_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1.] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import numpy as np\n",
    "# gerando 50 amostras\n",
    "X, y = np.ones((50, 1)), np.hstack(([0] * 45, [1] * 5))\n",
    "print(X[:,0], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  [30  3]   |   test -  [15  2]\n",
      "train -  [30  3]   |   test -  [15  2]\n",
      "train -  [30  4]   |   test -  [15  1]\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train, test in skf.split(X, y):\n",
    "    print('train -  {}   |   test -  {}'.format(\n",
    "        np.bincount(y[train]), np.bincount(y[test])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  [28  5]   |   test -  [17]\n",
      "train -  [28  5]   |   test -  [17]\n",
      "train -  [34]   |   test -  [11  5]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "for train, test in kf.split(X, y):\n",
    "    print('train -  {}   |   test -  {}'.format(\n",
    "        np.bincount(y[train]), np.bincount(y[test])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que `StratifiedKFold` preserva a razão das classes (aproximadamente 1/10) tanto para os conjuntos de treinamento quanto de teste.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otimizando os hyper-parâmetros de um modelo\n",
    "\n",
    "Hyper-parâmetros são parametros que não são aprendidos diretamente pelo modelo, e geralmente precisam ser escolhidos pelo usuário. Alguns exemplos típicos são o $C$ do Regressor Logístico, e o learning rate das redes neurais.\n",
    "\n",
    "Uma prática recomendada é percorrer o espaço de busca desses hyper-parâmetros a fim de encontrar o melhor resultado utilizando a validação cruzada.\n",
    "\n",
    "O Scikit-Learn oferece duas opções genéricas para encontrar esses valores: [GridSearchCV ](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV), que faz uma busca exaustiva considerando todas as possíveis combinações de parametros, e [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV), que seleciona um determinado número de combinações candidatas do espaço de busca usando uma distribuição específica. Ambas possuem uma contrapartida mais eficiente que vai reduzindo as opções pela metade, i.e., [HalvingGridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV) e [HalvingRandomSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search exaustivo\n",
    "\n",
    "Faz uma busca exaustiva por todas as possíveis combinações de parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Otimizando os hyper-parameters para precision\n",
      "\n",
      "Melhor conjunto de parâmetros encontrados durante treinamento com validação cruzada:\n",
      "\n",
      "{'C': 1}\n",
      "\n",
      "Resultado da validação cruzada para cada combinação da grade:\n",
      "\n",
      "0.967 (+/-0.011) for {'C': 1}\n",
      "0.964 (+/-0.016) for {'C': 10}\n",
      "0.964 (+/-0.013) for {'C': 100}\n",
      "0.962 (+/-0.024) for {'C': 1000}\n",
      "\n",
      "Relatório de classificação detalhado:\n",
      "\n",
      "O modelo é treinado sobre todo o conjunto de treinamento.\n",
      "As métricas são computadas apenas considerando o conjunto de testes.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        89\n",
      "           1       0.94      0.94      0.94        90\n",
      "           2       0.99      0.98      0.98        92\n",
      "           3       0.96      0.96      0.96        93\n",
      "           4       0.97      0.97      0.97        76\n",
      "           5       0.91      0.94      0.93       108\n",
      "           6       0.98      0.98      0.98        89\n",
      "           7       0.97      0.99      0.98        78\n",
      "           8       0.95      0.85      0.90        92\n",
      "           9       0.89      0.95      0.92        92\n",
      "\n",
      "    accuracy                           0.95       899\n",
      "   macro avg       0.96      0.96      0.96       899\n",
      "weighted avg       0.96      0.95      0.95       899\n",
      "\n",
      "\n",
      "# Otimizando os hyper-parameters para recall\n",
      "\n",
      "Melhor conjunto de parâmetros encontrados durante treinamento com validação cruzada:\n",
      "\n",
      "{'C': 1}\n",
      "\n",
      "Resultado da validação cruzada para cada combinação da grade:\n",
      "\n",
      "0.963 (+/-0.010) for {'C': 1}\n",
      "0.960 (+/-0.017) for {'C': 10}\n",
      "0.960 (+/-0.015) for {'C': 100}\n",
      "0.958 (+/-0.027) for {'C': 1000}\n",
      "\n",
      "Relatório de classificação detalhado:\n",
      "\n",
      "O modelo é treinado sobre todo o conjunto de treinamento.\n",
      "As métricas são computadas apenas considerando o conjunto de testes.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        89\n",
      "           1       0.94      0.94      0.94        90\n",
      "           2       0.99      0.98      0.98        92\n",
      "           3       0.96      0.96      0.96        93\n",
      "           4       0.97      0.97      0.97        76\n",
      "           5       0.91      0.94      0.93       108\n",
      "           6       0.98      0.98      0.98        89\n",
      "           7       0.97      0.99      0.98        78\n",
      "           8       0.95      0.85      0.90        92\n",
      "           9       0.89      0.95      0.92        92\n",
      "\n",
      "    accuracy                           0.95       899\n",
      "   macro avg       0.96      0.96      0.96       899\n",
      "weighted avg       0.96      0.95      0.95       899\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Carrega o dataset digits\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# converte as imagens de matrizes (2D) para vetores 1D\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "\n",
    "# divide o conjunto em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Seta os possíveis hiper-parâmetros\n",
    "tuned_parameters = [{'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "# métricas\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Otimizando os hyper-parameters para %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        LogisticRegression(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Melhor conjunto de parâmetros encontrados durante treinamento com validação cruzada:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Resultado da validação cruzada para cada combinação da grade:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Relatório de classificação detalhado:\")\n",
    "    print()\n",
    "    print(\"O modelo é treinado sobre todo o conjunto de treinamento.\")\n",
    "    print(\"As métricas são computadas apenas considerando o conjunto de testes.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busca aleatória\n",
    "\n",
    "Enquanto o grid search busca exaustivamente o melhor resultado testando todas as possíveis combinações de valores, `RandomizedSearchCV` implementa uma busca aleatória, sorteando $n$ possíveis valores dentro de uma distribuição. Essa abordagem possui 2 vantagens em relação ao _grid search_:\n",
    "\n",
    "\n",
    "- O custo computacional pode ser definido independentemente do número de parâmetros e possíveis combinações (escolhe de ante-mão quantas vezes a busca será executada).\n",
    "\n",
    "- Adicionar parâmetros que não influenciam na performance do modelo não vão influenciar no tempo de busca (mais parâmetros não implica em maior número de execuções)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV levou 15.38 segundos para 20 combinações candidatas.\n",
      "Modelo com rank: 1\n",
      "Media sobre conjunto de validação: 0.914 (desvio: 0.027)\n",
      "Parâmetros: {'penalty': 'l2', 'C': 1}\n",
      "\n",
      "Modelo com rank: 2\n",
      "Media sobre conjunto de validação: 0.911 (desvio: 0.031)\n",
      "Parâmetros: {'penalty': 'l2', 'C': 12}\n",
      "\n",
      "Modelo com rank: 3\n",
      "Media sobre conjunto de validação: 0.911 (desvio: 0.028)\n",
      "Parâmetros: {'penalty': 'l2', 'C': 50}\n",
      "\n",
      "GridSearchCV levou 153.40 segundos para 198 combinações candidatas\n",
      "Modelo com rank: 1\n",
      "Media sobre conjunto de validação: 0.914 (desvio: 0.027)\n",
      "Parâmetros: {'C': 1, 'penalty': 'l2'}\n",
      "\n",
      "Modelo com rank: 2\n",
      "Media sobre conjunto de validação: 0.913 (desvio: 0.030)\n",
      "Parâmetros: {'C': 3, 'penalty': 'l2'}\n",
      "\n",
      "Modelo com rank: 3\n",
      "Media sobre conjunto de validação: 0.912 (desvio: 0.031)\n",
      "Parâmetros: {'C': 8, 'penalty': 'l2'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "import scipy.stats as stats\n",
    "from sklearn.utils.fixes import loguniform\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# baixando o dataset\n",
    "X, y = load_digits(return_X_y=True)\n",
    "\n",
    "# construindo um classificador\n",
    "clf = LogisticRegression()\n",
    "\n",
    "\n",
    "# função para processar o resultado\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Modelo com rank: {0}\".format(i))\n",
    "            print(\"Media sobre conjunto de validação: {0:.3f} (desvio: {1:.3f})\"\n",
    "                  .format(results['mean_test_score'][candidate],\n",
    "                          results['std_test_score'][candidate]))\n",
    "            print(\"Parâmetros: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# especificando os parâmetros e distribuições\n",
    "param_dist = {'penalty': ['l1', 'l2'],\n",
    "              'C': np.arange(1,100,1)}\n",
    "\n",
    "# executando a busca aleatória\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV levou %.2f segundos para %d combinações\"\n",
    "      \" candidatas.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# usando o grid search completo\n",
    "param_grid = {'penalty': ['l1', 'l2'],\n",
    "              'C': np.arange(1,100,1)}\n",
    "\n",
    "# executando o grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV levou %.2f segundos para %d combinações candidatas\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
